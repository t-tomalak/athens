# This is an example configuration with all supported properties explicitly set
# Most properties can be overridden with environment variables specified in this file
# Most properties also have defaults (mentioned in this file) if they are not set in either the config file or the corresponding environment variable

# GoBinary returns the path to the go binary to use. This value can be a name of a binary in your PATH, or the full path
# Defaults to "go"
# Env override: GO_BINARY_PATH
GoBinary = "go"

# GoEnv specifies the type of environment to run.
# Supported values are: 'development' and 'production'. Defaults to "development"
# Env override: GO_ENV
GoEnv = "development"

# GoGetWorkers specifies how many times you can concurrently
# go mod download, this is so that low performance instances
# can manage go get more sanely and not run out of disk or memory.
# Env override: ATHENS_GOGET_WORKERS
GoGetWorkers = 30

# ProtocolWorkers specifies how many concurrent
# requests can you handle at a time for all
# download protocol paths. This is different from
# GoGetWorkers in that you can potentially serve
# 30 requests to the Download Protocol but only 5
# at a time can stash a module from Upstream to Storage.
# Env override: ATHENS_PROTOCOL_WORKERS
ProtocolWorkers = 30

# LogLevel returns the system's exposure to internal logs. Defaults to debug.
# Supports all logrus log levels (https://github.com/Sirupsen/logrus#level-logging)
# Env override: ATHENS_LOG_LEVEL
LogLevel = "debug"

# BuffaloLogLevel returns the log level for logs
# emitted by Buffalo itself. This is different from our own
# LogLevel in this file because you might want info level
# for our codebase, but panic level for buffalo.
# Env override: BUFFALO_LOG_LEVEL
BuffaloLogLevel = "debug"

# CloudRuntime is the Cloud Provider on which the Proxy/Registry is running.
# Currently available options are "GCP", or "none". Defaults to "none"
# Env override: ATHENS_CLOUD_RUNTIME
CloudRuntime = "none"

# The filename for the include exclude filter.
# Env override: ATHENS_FILTER_FILE
FilterFile = ""

# Timeout is the timeout for external network calls in seconds
# This value is used as the default for storage backends if they don't specify timeouts
# Defaults to 300
# Env override: ATHENS_TIMEOUT
Timeout = 300

# StorageType sets the type of storage backend the proxy will use.
# Possible values are memory, disk, mongo, gcp, minio, s3
# Defaults to memory
# Env override: ATHENS_STORAGE_TYPE
StorageType = "memory"

# Port sets the port the proxy listens on
# Env override: PORT
Port = ":3000"

# The endpoint for a package registry in case of a proxy cache miss
# NOTE: Currently no registries have been implemented
# Env override: ATHENS_GLOBAL_ENDPOINT
GlobalEndpoint = "http://localhost:3001"

# Username for basic auth
# Env override: BASIC_AUTH_USER
BasicAuthUser = ""

# Password for basic auth
# Env override: BASIC_AUTH_PASS
BasicAuthPass = ""

# Set to true to force an SSL redirect
# Env override: PROXY_FORCE_SSL
ForceSSL = false

# ValidatorHook specifies the endpoint to validate modules against
# Not used if left blank or not specified
# Env override: ATHENS_PROXY_VALIDATOR
ValidatorHook = ""

# PathPrefix specifies whether the Proxy
# should have a basepath. Certain proxies and services
# are distinguished based on subdomain, while others are based
# on path prefixes.
# Env override: ATHENS_PATH_PREFIX
PathPrefix = ""

# NETRCPath tells you where the .netrc path initially resides.
# This is so that you can mount the .netrc file to a secret location
# in the fs system and then move it ~/.netrc. In certain deployments
# like Kubernetes, we can't mount directly to ~ because it would then
# clean out whatever is already there as part of the image (such as
# .cache directory in the Go image).
# Env override: ATHENS_NETRC_PATH
NETRCPath = ""

# GithubToken can be used instead of a NETRCPath to authenticate
# the proxy to your own private repos on github. This makes it
# easier for users and for platforms like GAE to only be provided
# a Github token instead of a .netrc file. Internally, the proxy
# just create a .netrc file for you.
# Env override: ATHENS_GITHUB_TOKEN
GithubToken = ""

# HGRCPath tells you where the .hgrc path initially resides.
# This is so that you can mount the .hgrc file to a secret location
# in the fs system and then move it ~/.hgrc. In certain deployments
# like Kubernetes, we can't mount directly to ~ because it would then
# clean out whatever is already there as part of the image (such as
# .cache directory in the Go image).
# Env override: ATHENS_HGRC_PATH
HGRCPath = ""

# TraceExporterURL is the URL to which Athens populates distributed tracing
# information such as Jaeger. In Stackdriver, use this as the GCP ProjectID.
# Env override: ATHENS_TRACE_EXPORTER_URL
TraceExporterURL = ""

# TraceExporter is the service to which the data collected by OpenCensus can be exported to.
# Possible values are: jaeger, datadog, and stackdriver.
# Env overide: ATHENS_TRACE_EXPORTER
TraceExporter = ""

[Storage]
    # Only storage backends that are specified in Proxy.StorageType are required here
    [Storage.CDN]
        # Endpoint for CDN storage
        # Env override: CDN_ENDPOINT
        Endpoint = "cdn.example.com"

        # Timeout for networks calls made to the CDN in seconds
        # Defaults to Global Timeout
        Timeout = 300

    [Storage.Disk]
        # RootPath is the Athens Disk Root folder
        # Env override: ATHENS_DISK_STORAGE_ROOT
        RootPath = "/path/on/disk"

    [Storage.GCP]
        # ProjectID to use for GCP Storage
        # Env overide: GOOGLE_CLOUD_PROJECT
        ProjectID = "MY_GCP_PROJECT_ID"

        # Bucket to use for GCP Storage
        # Env override: ATHENS_STORAGE_GCP_BUCKET
        Bucket = "MY_GCP_BUCKET"

        # Timeout for networks calls made to GCP in seconds
        # Defaults to Global Timeout
        Timeout = 300

    [Storage.Minio]
        # Endpoint for Minio storage
        # Env override: ATHENS_MINIO_ENDPOINT
        Endpoint = "127.0.0.1:9001"

        # Access Key for Minio storage
        # Env override: ATHENS_MINIO_ACCESS_KEY_ID
        Key = "minio"

        # Secret Key for Minio storage
        # Env override: ATHENS_MINIO_SECRET_ACCESS_KEY
        Secret = "minio123"

        # Timeout for networks calls made to Minio in seconds
        # Defaults to Global Timeout
        Timeout = 300

        # Enable SSL for Minio connections
        # Defaults to true
        # Env override: ATHENS_MINIO_USE_SSL
        EnableSSL = false

        # Minio Bucket to use for storage
        # Defaults to gomods
        # Env override: ATHENS_MINIO_BUCKET_NAME
        Bucket = "gomods"

        # Region for Minio storage
        # Env override: ATHENS_MINIO_REGION
        Region = ""

    [Storage.Mongo]
        # Full URL for mongo storage
        # Env override: ATHENS_MONGO_STORAGE_URL
        URL = "mongodb://127.0.0.1:27017"

        # Path to certificate to use for the mongo connection
        # Env override: ATHENS_MONGO_CERT_PATH
        CertPath = ""

        # Timeout for networks calls made to Mongo in seconds
        # Defaults to Global Timeout
        # Env override: MONGO_CONN_TIMEOUT_SEC
        Timeout = 300

        # Allows for insecure SSL / http connections to mongo storage
        # Should be used for testing or development only
        # Env override: ATHENS_MONGO_INSECURE
        Insecure = false
        
    [Storage.S3]
        # Access Key for S3 storage
        # Env override: AWS_REGION
        Region = "MY_AWS_REGION"

        # Access Key for S3 storage
        # Env override: AWS_ACCESS_KEY_ID
        Key = "MY_AWS_ACCESS_KEY_ID"

        # Secret Key for S3 storage
        # Env override: AWS_SECRET_ACCESS_KEY
        Secret = "MY_AWS_SECRET_ACCESS_KEY"

        # Session Token for S3 storage
        # Env override: AWS_SESSION_TOKEN
        Token = ""

        # Timeout for networks calls made to S3 in seconds
        # Defaults to Global Timeout
        Timeout = 300

        # S3 Bucket to use for storage
        # Defaults to gomods
        # Env override: ATHENS_S3_BUCKET_NAME
        Bucket = "MY_S3_BUCKET_NAME"
